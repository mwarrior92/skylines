\section{Common Network Resource Exposure} \label{sect:cnre}

This project seeks to explore aggregate network resource catchments --- the set of
users exposed to the same set of web resources as each other across a given set
of domains. We introduce a new similarity measure, which we have coined common
network resource exposure (CNRE), to quantify the extent to which two clients
are exposed to the same network resources. Inspired by the Jaccard index \cite{jaccard1908nouvelles},
CNRE between two clients, $C_1$ and $C_2$, is defined as follows:

\[ \textrm{CNRE}(C_1, C_2) = \frac{ \sum_{i}^D  m_{i} (r_{1_i}^{-1}+r_{2_i}^{-1})}{ \sum_{i}^D (r_{1_i}^{-1}+r_{2_i}^{-1})} \]

where $D$ represents the intersection of measured domains between both clients, 
and $m_{i}$ is 1 if $C_{1}$ and $C_{2}$'s
$i$\textsuperscript{th} domain answers match (otherwise zero). The values
$r_{1_i}$ and $r_{2_i}$ represent the fraction of all measurements (across the
entire dataset) that matched $C_1$'s and $C_2$'s DNS answer for that domain,
respectively. For example, if $C_1$'s answer for domain $i$ appeared 900 times
across the 9024 times it was tested in the dataset (once by client), 
\(r_{1_i} =  900 / 9024\), or 0.09973 (\emph{i.e.} roughly 10\% of the answers). 
In other words, $r_{n_i}$ captures the
\emph{rarity} of the DNS answer received by client $C_n$ for domain $i$.

In our calculation of CNRE, we use the inverse of $r_{n_i}$ to add increased
weight to the impact of a match on rare answers. CNRE is therefore designed
to be higher between clients with more matching rare answers. As it is
ultimately a measure of similarity between clients, CNRE values range from 0
through 1, with 1 being the most similar. To ease discussion in the remainder of
this project, here we also define CNRE \emph{distance} as \(1 - \)CNRE. Likewise, where
ambiguity is likely, we will refer to raw CNRE as CNRE \emph{similarity}. 

\begin{figure}
    \epsfig{file=figs/90th.png, width=1\linewidth}
    \caption{CDF showing the effect of the number of domains used for CNRE
    calculation. The 500 clients and set of domains used for each CNRE
    calculation were randomized.}
    \label{fig:90cnre}
\end{figure}

In Figure \ref{fig:90cnre}, we plot the effects of the number of domains on CNRE
statistics. For each data point, we performed pairwise CNRE calculations between
500, randomly selected clients. For each individual comparison, a random set of
domains were selected, matching the quantity being tested. Both upper
(90\textsuperscript{th}
percentile) and lower (10\textsuperscript{th}) CNRE scores stabilize and plateau
significantly by 150 domains, showing no substantial changes as the
number of domains increases beyond that. This validates our use of 160 domains
as a cutoff for a client's admission into the final dataset.

\begin{figure}
    \epsfig{file=figs/domain_error.png, width=1\linewidth}
    \caption{Mean domain error vs \# of distinct answers observed from domain
    (one point per domain).}
    \label{fig:domerr}
\end{figure}

We pause here to address potential bias given toward individual domains. As CNRE
calculation gives increased weight to rare answers, there is the possibility
that the allocation patterns of large providers (who often have more answer
variety related to the scale of their networks) may dominate the results. This
would be detrimental to the main purpose of CNRE --- a supposedly aggregate
measure --- as it would ultimately revert to essentially measuring a single
provider, which is a well explored topic. To determine whether this is occurring,
we calculate the \emph{domain error}, for a single domain, as follows: Given a
pair of clients, first, find their CNRE normally. Next, let us set $d$ to be 1
if the DNS answer for the domain of interest matches between the pair of
clients, and otherwise 0. Finally, the domain error is the absolute value of \(d
- \)CNRE. In Figure \ref{fig:domerr}, we plot this, with each
point representing the mean domain error for a given domain across
the entire set of client combinations. 

With domain error, we capture how different the CNRE would have
been had that domain been the only one used in that client pair's CNRE calculation. A \emph{low}
mean domain
error --- close to zero --- implies that the domain is dominating over the
CNRE. A \emph{high} mean domain error --- close to one --- implies that the domain has little impact
on CNRE's value. A mean domain error close to the middle --- 0.5 --- is ideal,
as it implies that the domain is neither dominant nor irrelevant. We see in
Figure \ref{fig:domerr} that domains with many answers (and hence increased rarity per
answer) actually have the highest error. Further, the range of domain error
across all domains spans roughly from 0.4 to 0.6, indicative of the absence of
substantial bias towards any given domain from our approach.
